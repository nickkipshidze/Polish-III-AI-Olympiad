{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e3k0aqA7BJrB",
      "metadata": {
        "id": "e3k0aqA7BJrB"
      },
      "source": [
        "# Klasyfikacja wieloetykietowa\n",
        "\n",
        "![multilabel_intro.png](https://live.staticflickr.com/65535/54927204610_28ff033051.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MMmQE_4lEZi-",
      "metadata": {
        "id": "MMmQE_4lEZi-"
      },
      "source": [
        "*Obraz wygenerowany przez narzędzie generowania obrazów ChatGPT.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9T57js6l62KY",
      "metadata": {
        "id": "9T57js6l62KY"
      },
      "source": [
        "## Wstęp\n",
        "\n",
        "Współczesne zdjęcia często zawierają wiele obiektów i złożone sceny. Przykładem jest fotografia powyżej: widzimy na niej mężczyznę w marynarce, koszuli i krawacie, kobietę w sukni z welonem, grupę osób w letnich ubraniach, a całość rozgrywa się na plaży, na tle wody i zachodu słońca.\n",
        "\n",
        "Gdybyśmy trzymali się klasycznego podejścia „jedno zdjęcie — jedna etykieta”, musielibyśmy wybrać tylko jedną kategorię: czy to zdjęcie przedstawia ślub, mężczyznę, kobietę, marynarkę, suknię, plażę…? W praktyce oznacza to sztuczne ograniczenie informacji.\n",
        "\n",
        "Nie musimy jednak ograniczać się do jednej etykiety. Właśnie dlatego stosuje się klasyfikację wieloetykietową, która pozwala przypisać jednemu obrazowi wiele kategorii opisujących różne obiekty.\n",
        "Zamiast wybierać jedną etykietę, możemy więc powiedzieć:\n",
        "„Na tym zdjęciu występują instancje klas: człowiek, marynarka, koszula, krawat, suknia, plaża itd.”"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7EcxNFYcETLi",
      "metadata": {
        "id": "7EcxNFYcETLi"
      },
      "source": [
        "## Zadanie\n",
        "\n",
        "Twoim zadaniem jest zdefiniowanie i wytrenowanie sieci neuronowej do realizacji klasyfikacji wieloetykietowej. W zadaniu kompozycja zdjęcia będzie uproszczona w stosunku do przykładu powyżej. Na zdjęciach będą widoczne tylko ubrania, a Twoim zadaniem jest stworzenie modelu, który potrafi określić, czy dany rodzaj ubrania występuje na zdjęciu.\n",
        "\n",
        "## Dane\n",
        "\n",
        "W zadaniu masz do dyspozycji \n",
        "* zbiór treningowy ($6318$ próbek),\n",
        "* zbiór walidacyjny ($702$ próbek). \n",
        "\n",
        "Zbiór testowy, na którym finalnie będzie oceniane Twoje rozwiązanie ma 780 próbek i jest niejawny. Został on stworzony w ten sam sposób co zbiór walidacyjny więc ma analogiczną charakterystykę.\n",
        "\n",
        "Każda próbka to obraz o wymiarach $168 \\times 168$ pikseli. Z każdym obrazkiem skojarzony jest 10-elementowy wektor z wartościami $0$ i $1$, który określa obecność danej klasy na obrazku. Informacja o tym jakiej części garderoby odpowiada poszczególny indeks w wektorze etykiet jest podana w słowniku `LABEL_NAMES` zdefiniowanym w jednej z komórek z kodem.\n",
        "\n",
        "## Kryterium Oceny\n",
        "Ostateczna ocena zadania będzie na podstawie średniej wartości miary $F1$ policzonej w ramach schematu *macro*.\n",
        "\n",
        "Za to zadanie możesz zdobyć pomiędzy 0 a 100 punktów. Twój finalny wynik punktowy za rozwiązanie zadania obliczony będzie według poniższej funkcji (im wyższa wartość tym lepiej) przy dodatkowym zastosowaniu zaokrąglenia do wartości całkowitych:\n",
        "$$\n",
        "\\mathrm{score} =\n",
        "\\begin{cases}\n",
        "    0 & \\text{jeżeli } {F1}\\leq 0.57 \\\\\n",
        "    100 \\times \\frac{{F1}- 0.57}{0.87 - 0.57} & \\text{jeżeli } 0.57 < {F1} < 0.87 \\\\\n",
        "    100 & \\text{jeżeli } {F1} \\geq 0.87\n",
        "\\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MQ1pFuH7GVV5",
      "metadata": {
        "id": "MQ1pFuH7GVV5"
      },
      "source": [
        "## Ograniczenia\n",
        "\n",
        "- Twoje rozwiązanie będzie testowane na Platformie Konkursowej w środowisku z GPU. Na Platformie nie ma dostępu do Internetu, jednak możliwe jest skorzystanie z pretrenowanych modeli ResNet (*ResNet18*, *ResNet34*, *ResNet50*) z pakietu torchvision, które są zapisane w pamięci w formie plików. Aby z nich skorzystać, należy zastosować taką samą komendę w kodzie jak w przypadkach gdy Internet jest dostępny.\n",
        "- Ewaluacja Twojego finalnego rozwiązania na danych testowych na Platformie Konkursowej nie może trwać dłużej niż 2.5 minuty z GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ORy1u6zI0Sj",
      "metadata": {
        "id": "8ORy1u6zI0Sj"
      },
      "source": [
        "## Pliki zgłoszeniowe\n",
        "\n",
        "Ten notebook uzupełniony o Twoje rozwiązanie (definicję modelu, funkcję do treningu modelu i funkcję zwracającą predykcje modelu)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cmv0uOZJFVX",
      "metadata": {
        "id": "0cmv0uOZJFVX"
      },
      "source": [
        "## Ewaluacja\n",
        "\n",
        "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`.\n",
        "\n",
        "Za to zadanie możesz zdobyć pomiędzy 0 a 100 punktów. Liczba punktów, którą zdobędziesz, będzie wyliczona na (tajnym) zbiorze testowym na Platformie Konkursowej na podstawie wyżej wspomnianego wzoru, zaokrąglona do liczby całkowitej. Jeśli Twoje rozwiązanie nie będzie spełniało powyższych kryteriów lub nie będzie wykonywać się prawidłowo, otrzymasz za zadanie 0 punktów."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QmBsQiHMJUmT",
      "metadata": {
        "id": "QmBsQiHMJUmT"
      },
      "source": [
        "## Kod Startowy\n",
        "W tej sekcji inicjalizujemy środowisko poprzez zaimportowanie potrzebnych bibliotek i funkcji. Przygotowany kod ułatwi Tobie efektywne operowanie na danych i budowanie właściwego rozwiązania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20227718",
      "metadata": {
        "id": "20227718"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "FINAL_EVALUATION_MODE: bool = False  # Podczas sprawdzania ustawimy tę flagę na True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecfbaca7",
      "metadata": {
        "id": "ecfbaca7"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as fun\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3a78cbb",
      "metadata": {
        "id": "d3a78cbb"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "    \"\"\"Ustawia ziarno (seed) dla reprodukowalności wyników w Pythonie, NumPy oraz PyTorch.\"\"\"\n",
        "\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21d6d8c6",
      "metadata": {
        "id": "21d6d8c6"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "# liczba klas do klasyfikacji\n",
        "N_CLASSES: int = 10\n",
        "\n",
        "# mapowanie indeksu klasy na jej nazwę\n",
        "LABEL_NAMES: dict[int, str] = {\n",
        "    0: \"T-shirt/top\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle boot\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7237b743",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7237b743",
        "outputId": "32c561e9-d8fb-49a1-8443-3fe5e542573e"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    FILES: list[str] = [\n",
        "        \"runway-mnist/train-x.npz\",\n",
        "        \"runway-mnist/train-y.npz\",\n",
        "        \"runway-mnist/val-x.npz\",\n",
        "        \"runway-mnist/val-y.npz\"\n",
        "    ]\n",
        "\n",
        "    # pobierz dane na nowo, jeśli czegoś brakuje\n",
        "    if not all(os.path.exists(file) for file in FILES):\n",
        "        import gzip\n",
        "        import tarfile\n",
        "        import shutil\n",
        "\n",
        "        if not os.path.exists(\"runway-mnist\"):\n",
        "            os.mkdir(\"runway-mnist\")\n",
        "\n",
        "        COMPRESSED_ARCHIVE = \"runway-mnist.tar.gz\"\n",
        "        TAR_ARCHIVE  = COMPRESSED_ARCHIVE.rstrip(\".gz\")\n",
        "        DOWNLOAD_URL = \"https://drive.google.com/uc?id=1oNAFYdJyCVe3Po90KLUPxAG9HGuL7NSw\"\n",
        "\n",
        "        try:\n",
        "            import gdown\n",
        "        except ImportError as err:\n",
        "            raise RuntimeError(\"Do pobrania zbioru danych potrzebujesz lokalnej instalacji pakietu gdown: `pip install gdown`\") from err\n",
        "\n",
        "        gdown.download(DOWNLOAD_URL, str(COMPRESSED_ARCHIVE), quiet=False)\n",
        "\n",
        "        with gzip.open(COMPRESSED_ARCHIVE, \"rb\") as compressed:\n",
        "            with open(TAR_ARCHIVE, \"wb\") as archive:\n",
        "                shutil.copyfileobj(compressed, archive)\n",
        "\n",
        "        os.remove(COMPRESSED_ARCHIVE)\n",
        "        print(f\"Zdekompresowano: {TAR_ARCHIVE}\")\n",
        "\n",
        "        with tarfile.open(TAR_ARCHIVE, \"r\") as tar:\n",
        "            tar.extractall(\"runway-mnist\")\n",
        "\n",
        "        os.remove(TAR_ARCHIVE)\n",
        "        print(f\"Rozpakowano: {TAR_ARCHIVE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab20950b",
      "metadata": {
        "id": "ab20950b"
      },
      "source": [
        "### Ładowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f745b68",
      "metadata": {
        "id": "5f745b68"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "SEED: int = 42\n",
        "seed_everything(SEED)\n",
        "\n",
        "def load_x(usage) -> torch.Tensor:\n",
        "    path = f\"runway-mnist/{usage}-x.npz\"\n",
        "    return torch.tensor(np.load(path)[\"images\"], dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "def load_y(usage) -> torch.Tensor:\n",
        "    path = f\"runway-mnist/{usage}-y.npz\"\n",
        "    return torch.tensor(np.load(path)[\"labels\"], dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(load_x(\"train\"), load_y(\"train\"))\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "val_dataset = TensorDataset(load_x(\"val\"), load_y(\"val\"))\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yia0xt1UOWp1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yia0xt1UOWp1",
        "outputId": "088f3ade-46d8-483a-a21b-0cdfadafe7bb"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kEF6HG49U5Hs",
      "metadata": {
        "id": "kEF6HG49U5Hs"
      },
      "source": [
        "## Funkcja oceniająca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AVmPb9_4Uwy6",
      "metadata": {
        "id": "AVmPb9_4Uwy6"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "def compute_score(f1: float) -> int:\n",
        "    \"\"\"Oblicza wynik punktowy na podstawie wartości metryki F1.\"\"\"\n",
        "    lower_bound = 0.57\n",
        "    upper_bound = 0.87\n",
        "\n",
        "    if f1 <= lower_bound:\n",
        "        return 0\n",
        "    elif lower_bound < f1 < upper_bound:\n",
        "        return int(round(100 * (f1 - lower_bound) / (upper_bound - lower_bound)))\n",
        "    else:\n",
        "        return 100\n",
        "\n",
        "def evaluate_algorithm(model, predict, loader) -> float:\n",
        "    \"\"\"Oblicza metryki oraz ocenia Twoje rozwiązanie na ich podstawie. Zwraca obliczoną wartość metryki F1.\"\"\"\n",
        "    preds = []\n",
        "    labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            prediction = predict(model, x.to(device)).cpu()\n",
        "            preds.append(prediction)\n",
        "            labels.append(y)\n",
        "\n",
        "    predictions = torch.cat(preds)\n",
        "    labels = torch.cat(labels)\n",
        "\n",
        "    f1 = f1_score(labels.numpy(), predictions.numpy(), average=\"macro\")\n",
        "    points = compute_score(f1)\n",
        "    print(f\"Twój wynik F1: {f1:.3f}, co daje {points} punktów.\")\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qI41nLIwOFU7",
      "metadata": {
        "id": "qI41nLIwOFU7"
      },
      "source": [
        "## Przykładowe rozwiązanie\n",
        "\n",
        "Poniżej przedstawiamy uproszczone rozwiązanie, które demonstruje podstawową funkcjonalność\n",
        "notebooka. Może ono posłużyć jako punkt wyjścia do opracowania Twojego rozwiązania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_2OseGs_yv5p",
      "metadata": {
        "id": "_2OseGs_yv5p"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "class NaiveSolution(nn.Module):\n",
        "    \"\"\"Rozwiązanie naiwne.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Ten naiwny model przewiduje, że wszystkie klasy są na obrazku.\"\"\"\n",
        "        BATCH_SIZE = input.size(0)\n",
        "        return torch.Tensor([1] * BATCH_SIZE * N_CLASSES).reshape(BATCH_SIZE, -1)\n",
        "\n",
        "def train_naive(_: NaiveSolution):\n",
        "    \"\"\"Model, nie wymaga treningu.\"\"\"\n",
        "    pass\n",
        "\n",
        "def predict_naive(model: NaiveSolution, input: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Nasz model zwraca od razu predykcje modelu, nie przetwarzamy ich dodatkowo.\"\"\"\n",
        "    return model(input).to(torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wghTY43NOB54",
      "metadata": {
        "id": "wghTY43NOB54"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    naive_solution = NaiveSolution().to(device)\n",
        "    naive_solution.train()\n",
        "    train_naive(naive_solution)\n",
        "    evaluate_algorithm(naive_solution, predict_naive, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "674369c6",
      "metadata": {
        "id": "674369c6"
      },
      "source": [
        "## Twoje rozwiązanie\n",
        "W komórce poniżej należy umieścić Twoje rozwiązanie. Wprowadzaj zmiany wyłącznie tutaj!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jee8jU5dOGgk",
      "metadata": {
        "id": "jee8jU5dOGgk"
      },
      "outputs": [],
      "source": [
        "class Solution(nn.Module):\n",
        "    \"\"\"Twoje rozwiązanie.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Inferencja modelu\"\"\"\n",
        "        BATCH_SIZE = input.size(0)\n",
        "        return torch.rand(BATCH_SIZE * N_CLASSES).reshape(BATCH_SIZE, -1)\n",
        "\n",
        "def train_solution(_: Solution):\n",
        "    \"\"\"Pętla treningowa dla Twojego modelu.\"\"\"\n",
        "    pass\n",
        "\n",
        "def predict_solution(model: Solution, input: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Klasyfikacja z użyciem modelu.\n",
        "    Wydzielenie tej funkcji ma na celu proste umożliwienie post-processing'u wyników z modelu.\"\"\"\n",
        "    predictions = model(input).round().to(torch.long)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xrVVaVW2YdzK",
      "metadata": {
        "id": "xrVVaVW2YdzK"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA #########################\n",
        "\n",
        "solution = Solution().to(device)\n",
        "solution.train()\n",
        "\n",
        "train_solution(solution)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce80497b",
      "metadata": {},
      "source": [
        "## Ewaluacja\n",
        "\n",
        "Poniższy kod będzie służył ewaluacji rozwiązania. Po wysłaniu rozwiązania do nas zostanie wykonana funkcja `evaluate_algorithm(solution, predict_solution)`, t.j. prawie identyczny kod jak niżej będzie się uruchamiał na zbiorze testowym dostępnym tylko dla sprawdzających zadania.\n",
        "\n",
        "Upewnij się przed wysłaniem, że cały notebook wykonuje się od początku do końca bez błędów i bez ingerencji użytkownika po wykonaniu polecenia `Run All`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JGayW_ezYLQM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGayW_ezYLQM",
        "outputId": "58df38b4-ecc9-4c9d-a94f-4a07f604f719"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA #########################\n",
        "\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    evaluate_algorithm(solution, predict_solution, val_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
