{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32480c71",
   "metadata": {},
   "source": [
    "# Semantic Word Changes\n",
    "\n",
    "<img src=\"https://live.staticflickr.com/65535/54942563983_f3baea0eee_c.jpg\" alt=\"Embedded Photo\" width=\"776\">\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The meanings of words in natural language change over time—some evolve gradually, while others undergo rapid semantic shifts. Thanks to historical text corpora, it is possible to train vector models that capture these historical differences.\n",
    "\n",
    "In this task, you will analyze **pre-trained embeddings (word2vec)** from two different eras:\n",
    "- **1900** — a model trained exclusively on data from the early 20th century\n",
    "- **1990** — a model trained on data close to the present day\n",
    "\n",
    "These two models were trained **completely independently**. Your task will be to use these representations to build a classifier that determines whether **the meaning of a given word has changed significantly between 1900 and 1990**.\n",
    "\n",
    "## Task\n",
    "\n",
    "You will build a **binary classifier** that, for a given word, will return a label:\n",
    "\n",
    "- **0 — semantically stable word**\n",
    "- **1 — a word whose meaning has changed**\n",
    "\n",
    "## Data\n",
    "\n",
    "- `train.csv` — training set (word + label)\n",
    "- `valid.csv` — validation set for local testing\n",
    "- `1900-vocab.pkl` and `1900-w.npy` — vocabulary and embedding matrix from 1900\n",
    "- `1990-vocab.pkl` and `1990-w.npy` — an analogous set for the year 1990\n",
    "\n",
    "## Evaluation Criterion\n",
    "\n",
    "To evaluate your solution, we use the **Balanced Accuracy** metric, which is the average of the classification accuracy for the positive class and the negative class. In other words:\n",
    "\n",
    "$$ \\text{Balanced Accuracy} = \\frac{1}{2}(\\text{TPR} + \\text{TNR}) $$\n",
    "\n",
    "which is the average of sensitivity (TPR) and specificity (TNR).\n",
    "This is a metric resistant to imbalanced datasets.\n",
    "\n",
    "You return **hard labels (0/1)**.\n",
    "\n",
    "The notebook contains an `evaluate_algorithm` function, which you can use to test your model on `valid.csv`.\n",
    "\n",
    "For this task, you can score between 0 and 100 points. The score will be scaled linearly depending on the Balanced Accuracy value:\n",
    "\n",
    "- **Balanced Accuracy ≤ 0.7**: 0 points.\n",
    "- **Balanced Accuracy ≥ 0.87**: 100 points.\n",
    "- **Values between 0.7 and 0.87**: scaled linearly.\n",
    "\n",
    "Formula for the score:\n",
    "$$\n",
    "\\text{Points} = \n",
    "\\begin{cases} \n",
    "0 & \\text{for } \\text{Balanced Accuracy} \\leq 0.7 \\\\\n",
    "100 \\times \\frac{\\text{Balanced Accuracy} - 0.7}{0.87 - 0.7} & \\text{for } 0.7 < \\text{Balanced Accuracy} < 0.87 \\\\\n",
    "100 & \\text{for } \\text{Balanced Accuracy} \\geq 0.87\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "## Constraints\n",
    "\n",
    "Your notebook will be run on the Competition Platform:\n",
    "\n",
    "- **without internet access**\n",
    "- without GPU access - **CPU only**\n",
    "- Time limit for notebook execution and evaluation on the test set: **5 minutes**\n",
    "- List of allowed libraries: `numpy`, `pandas`, `scikit-learn`, `matplotlib`, `tqdm`\n",
    "\n",
    "## Submission Files\n",
    "\n",
    "- This notebook completed with your solution:\n",
    "\n",
    "```python\n",
    "class SemanticChangeModel:\n",
    "    def fit(self, train_df):\n",
    "        ...\n",
    "    def predict_change(self, words: List[str]) -> List[int in {0,1}]:\n",
    "        ...\n",
    "```\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Remember that during the final check, the `FINAL_EVALUATION_MODE` flag will be set to `True`.\n",
    "\n",
    "For this task, you can score between 0 and 100 points. The number of points you earn will be calculated on a (secret) test set on the Competition Platform based on the aforementioned formula, rounded to the nearest integer. If your solution does not meet the above criteria or does not execute correctly, you will receive 0 points for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e26a3d",
   "metadata": {},
   "source": [
    "## Starter Code\n",
    "In this section, we initialize the environment by importing the necessary libraries and functions. The prepared code will help you to efficiently operate on the data and build the right solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34507cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT CHANGE THIS CELL FOR SUBMISSION ##########################\n",
    "\n",
    "FINAL_EVALUATION_MODE = False  # We will set this flag to True during evaluation.\n",
    "\n",
    "import os, json, pickle, shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "EMB_DIR  = DATA_DIR / 'embeddings'\n",
    "EMB_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95827c2d",
   "metadata": {},
   "source": [
    "## Downloading data (local only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c77ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT CHANGE THIS CELL FOR SUBMISSION ##########################\n",
    "\n",
    "# Note: The internet is disabled on the evaluation platform.\n",
    "# This block only runs locally (when FINAL_EVALUATION_MODE == False).\n",
    "\n",
    "GDRIVE_FILES = [\n",
    "    ('1rUGgDZcpwRZ5sRHGxxEh2f7ZJ0DRVDPL', EMB_DIR / '1900-vocab.pkl'),\n",
    "    ('1cYXPhghcawbMZ6vU2XyJUq7NOpBIKj5E', EMB_DIR / '1900-w.npy'),\n",
    "    ('1ApLkBn2ylvLMKNlNtvkMVde6RxnLJolI', EMB_DIR / '1990-vocab.pkl'),\n",
    "    ('1B3NLInA4Ty3lUaHNQgxtDTKJNtG0t0T1', EMB_DIR / '1990-w.npy'),\n",
    "    ('1hrOfZOq3BV1K0tWe6HSZG-OiZkGlCiYT', DATA_DIR / 'train.csv'),\n",
    "    ('1vndyCuDCBP6zLvNkF_YsKHgTQgulTjt_', DATA_DIR / 'valid.csv'),\n",
    "]\n",
    "\n",
    "def download_data():\n",
    "    try:\n",
    "        import gdown\n",
    "    except Exception as e:\n",
    "        raise RuntimeError('Install gdown locally: `pip install gdown`') from e\n",
    "\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    EMB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for fid, out_path in GDRIVE_FILES:\n",
    "        if out_path.exists():\n",
    "            print(f'Download skipped - file already exists: {out_path.name}')\n",
    "            continue\n",
    "        url = f'https://drive.google.com/uc?id={fid}'\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'Downloading -> {out_path.name}')\n",
    "        gdown.download(url, str(out_path), quiet=False)\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    download_data()\n",
    "    print('Download complete.')\n",
    "else:\n",
    "    print('FINAL_EVALUATION_MODE=True - skip download (data is provided on the platform).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa2ab3",
   "metadata": {},
   "source": [
    "## Loading embeddings and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f499c495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900: V=100,000, dim=300\n",
      "1990: V=100,000, dim=300\n",
      "        word  label\n",
      "0     lichen      0\n",
      "1    imaging      1\n",
      "2      devil      0\n",
      "3    prayers      0\n",
      "4  frankfort      1\n",
      "\n",
      "        word  label\n",
      "0  coastline      0\n",
      "1       yoke      0\n",
      "2     report      1\n",
      "3   language      0\n",
      "4       barn      0\n",
      "train: 2495, valid: 832\n"
     ]
    }
   ],
   "source": [
    "######################### DO NOT CHANGE THIS CELL FOR SUBMISSION ##########################\n",
    "\n",
    "def load_histwords_decade(decade: int, emb_dir: Path):\n",
    "    vocab_path = emb_dir / f'{decade}-vocab.pkl'\n",
    "    w_path     = emb_dir / f'{decade}-w.npy'\n",
    "    with open(vocab_path, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    W = np.load(w_path)\n",
    "    # L2 normalization\n",
    "    W = W / (np.linalg.norm(W, axis=1, keepdims=True) + 1e-12)\n",
    "    w2i = {w:i for i,w in enumerate(vocab)}\n",
    "    return vocab, W, w2i\n",
    "\n",
    "# Loading embeddings\n",
    "vocab_1900, W1900, w2i_1900 = load_histwords_decade(1900, EMB_DIR)\n",
    "vocab_1990, W1990, w2i_1990 = load_histwords_decade(1990, EMB_DIR)\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    print(f'1900: V={len(vocab_1900):,}, dim={W1900.shape[1]}')\n",
    "    print(f'1990: V={len(vocab_1990):,}, dim={W1990.shape[1]}')\n",
    "\n",
    "# Loading train/valid files\n",
    "train_path = DATA_DIR / 'train.csv'\n",
    "valid_path = DATA_DIR / 'valid.csv'\n",
    "assert train_path.exists() and valid_path.exists(), 'No train.csv / valid.csv in data/ folder'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "valid_df = pd.read_csv(valid_path)\n",
    "\n",
    "# Expected columns: word, label\n",
    "for c in ['word', 'label']:\n",
    "    assert c in train_df.columns and c in valid_df.columns, 'Expected columns: word, label'\n",
    "\n",
    "train_df['word'] = train_df['word'].astype(str).str.lower().str.strip()\n",
    "valid_df['word'] = valid_df['word'].astype(str).str.lower().str.strip()\n",
    "train_df['label'] = train_df['label'].astype(int)\n",
    "valid_df['label'] = valid_df['label'].astype(int)\n",
    "\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    print(train_df.head(5))\n",
    "    print()\n",
    "    print(valid_df.head(5))\n",
    "    print(f'train: {len(train_df)}, valid: {len(valid_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 sąsiadów w 1900:\n",
      "  intellect  (0.4798)\n",
      "  sagacity  (0.4282)\n",
      "  discernment  (0.3707)\n",
      "  understanding  (0.3688)\n",
      "  tact  (0.3659)\n",
      "  skill  (0.3643)\n",
      "  humanity  (0.3641)\n",
      "  honesty  (0.3598)\n",
      "  ability  (0.3517)\n",
      "  sensibility  (0.3512)\n",
      "\n",
      "Top 10 sąsiadów w 1990:\n",
      "  iq  (0.3773)\n",
      "  wechsler  (0.3542)\n",
      "  cia  (0.3362)\n",
      "  hinsley  (0.3301)\n",
      "  artificial  (0.3264)\n",
      "  afric  (0.3202)\n",
      "  binet  (0.3191)\n",
      "  aptitude  (0.3152)\n",
      "  abwehr  (0.3108)\n",
      "  abilities  (0.3070)\n"
     ]
    }
   ],
   "source": [
    "def print_neighbors(word, V, vocab, w2i, label):\n",
    "    vec = V[w2i[word]]\n",
    "    sims = V @ vec\n",
    "    sims[w2i[word]] = -np.inf\n",
    "    top = np.argsort(-sims)[:10]\n",
    "    print(f\"\\nTop 10 neighbors in {label}:\")\n",
    "    for i in top:\n",
    "        print(f\"  {vocab[i]}  ({sims[i]:.4f})\")\n",
    "\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    print_neighbors(\"intelligence\", W1900, vocab_1900, w2i_1900, \"1900\")\n",
    "    print_neighbors(\"intelligence\", W1990, vocab_1990, w2i_1990, \"1990\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b201a2",
   "metadata": {},
   "source": [
    "## Your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7dad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################  MODIFY ONLY THIS CELL  #########################\n",
    "# Implement your model as a class with the following methods:\n",
    "#   - __init__       : save embeddings + basic hyperparameters\n",
    "#   - fit(train_df)  : train on labeled data\n",
    "#   - predict_change(words) : return labels for a given list of words\n",
    "#\n",
    "# The evaluation code will receive an instance of the class and will only assume\n",
    "# that it has a .predict_change(words) method.\n",
    "\n",
    "class SemanticChangeModel:\n",
    "    def __init__(self, W1900, W1990, w2i_1900, w2i_1990):\n",
    "        \"\"\"\n",
    "        Store all expensive / global objects here. You can build\n",
    "        additional structures in the fit() method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        W1900, W1990 : np.ndarray [V, D]\n",
    "            Normalized embeddings for the years 1900 and 1990.\n",
    "        w2i_1900, w2i_1990 : dict\n",
    "            Mapping from word -> row index in the embeddings.\n",
    "        \"\"\"\n",
    "        self.W1900 = W1900\n",
    "        self.W1990 = W1990\n",
    "        self.w2i_1900 = w2i_1900\n",
    "        self.w2i_1990 = w2i_1990\n",
    "\n",
    "        # You can add more parameters and methods as needed\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"\n",
    "        Build your model using the labeled training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_df : pd.DataFrame\n",
    "            Must contain at least the columns ['word', 'label'].\n",
    "        \"\"\"\n",
    "        # TODO: replace this placeholder with your actual fitting logic.\n",
    "        pass\n",
    "    \n",
    "    def predict_change(self, words):\n",
    "        \"\"\"\n",
    "        Predicts whether words have significantly changed their meaning.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        words : list of str\n",
    "            A list of words to be classified.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of int\n",
    "            A list of 0s or 1s (1 = 'changed') for each word.\n",
    "        \"\"\"\n",
    "        # TODO: replace this placeholder with your actual prediction logic.\n",
    "        return [random.choice([0,1]) for _ in words]\n",
    "\n",
    "\n",
    "MODEL = SemanticChangeModel(W1900, W1990, w2i_1900, w2i_1990)\n",
    "MODEL.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e5527a",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Running the cell below will allow you to check how many points your solution would score on the validation data.\n",
    "\n",
    "Before submitting, make sure that the entire notebook runs from start to finish without errors and without user intervention after executing the `Run All` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39991ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Liczba próbek: 832\n",
      "Balanced accuracy: 0.5157\n",
      "Wynik punktowy: 0\n"
     ]
    }
   ],
   "source": [
    "######################### DO NOT CHANGE THIS CELL FOR SUBMISSION ##########################\n",
    "def compute_score(bal_acc: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the point score based on the balanced accuracy value.\n",
    "\n",
    "    :param bal_acc: A float value in the range [0.0, 1.0]\n",
    "    :return: A point score according to the specified function\n",
    "    \"\"\"\n",
    "    if bal_acc <= 0.7:\n",
    "        return 0\n",
    "    elif 0.7 < bal_acc < 0.87:\n",
    "        return int(round(100 * (bal_acc - 0.7) / (0.87 - 0.7)))\n",
    "    else:\n",
    "        return 100\n",
    "\n",
    "\n",
    "def evaluate_algorithm(dataset_df, model, verbose=False):\n",
    "    \"\"\"\n",
    "    Evaluation of a word sense change detection model on a given dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_df : pd.DataFrame\n",
    "        A labeled dataset with columns:\n",
    "          - 'word'  : word (string)\n",
    "          - 'label' : label 0 = stable, 1 = changed\n",
    "\n",
    "    model : object\n",
    "        An object with a method:\n",
    "            predict_change(words: list[str]) -> list[int] {0,1}\n",
    "\n",
    "    verbose : bool\n",
    "        If True, prints additional information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    points : float\n",
    "        A point score based on balanced accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract words and labels from the dataset\n",
    "    words = dataset_df[\"word\"].astype(str).tolist()\n",
    "    ys = dataset_df[\"label\"].astype(int).tolist()\n",
    "\n",
    "    # Get predictions for the entire list of words\n",
    "    preds = model.predict_change(words)\n",
    "\n",
    "    # Convert predictions and labels to numpy arrays\n",
    "    preds = np.array(preds, dtype=np.int32)\n",
    "    ys = np.array(ys, dtype=np.int32)\n",
    "\n",
    "    # Balanced accuracy\n",
    "    bal_acc = balanced_accuracy_score(ys, preds)\n",
    "\n",
    "    # Convert accuracy to competition points\n",
    "    points = compute_score(bal_acc)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nNumber of samples: {len(dataset_df)}\")\n",
    "        print(f\"Balanced accuracy: {bal_acc:.4f}\")\n",
    "        print(f\"Point score: {points}\")\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    _ = evaluate_algorithm(valid_df, MODEL, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
