{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32480c71",
   "metadata": {},
   "source": [
    "# Zmiany semantyczne słów\n",
    "\n",
    "<img src=\"https://live.staticflickr.com/65535/54942563983_f3baea0eee_c.jpg\" alt=\"Embedded Photo\" width=\"776\">\n",
    "\n",
    "## Wstęp\n",
    "\n",
    "Znaczenia słów w języku naturalnym zmieniają się wraz z czasem — jedne ewoluują stopniowo, inne przechodzą gwałtowne przesunięcia semantyczne. Dzięki dawnym korpusom tekstowym możliwe jest trenowanie modeli wektorowych, które uchwytują te historyczne różnice.\n",
    "\n",
    "W tym zadaniu będziesz analizować **pretrenowane embeddingi (word2vec)** z dwóch różnych epok:\n",
    "- **1900** — model wytrenowany wyłącznie na danych z początku XX wieku  \n",
    "- **1990** — model wytrenowany na danych bliskich współczesności  \n",
    "\n",
    "Te dwa modele zostały wytrenowane **całkowicie niezależnie**. Twoim zadaniem będzie wykorzystać te reprezentacje, aby zbudować klasyfikator określający, czy **znaczenie danego słowa uległo istotnej zmianie między rokiem 1900 a 1990**.\n",
    "\n",
    "## Zadanie\n",
    "\n",
    "Zbudujesz **klasyfikator binarny**, który dla zadanego słowa zwróci etykietę:\n",
    "\n",
    "- **0 — słowo stabilne semantycznie**\n",
    "- **1 — słowo, którego znaczenie się zmieniło**\n",
    "\n",
    "## Dane\n",
    "\n",
    "- `train.csv` — zbiór treningowy (słowo + etykieta)\n",
    "- `valid.csv` — zbiór walidacyjny do lokalnego testowania\n",
    "- `1900-vocab.pkl` oraz `1900-w.npy` — słownik i macierz embeddingów z 1900 roku  \n",
    "- `1990-vocab.pkl` oraz `1990-w.npy` — analogiczny zestaw dla roku 1990  \n",
    "\n",
    "## Kryterium oceny\n",
    "\n",
    "Do oceny Twojego rozwiązania wykorzystujemy metrykę **Balanced Accuracy**, czyli średnią dokładności klasyfikacji dla klasy pozytywnej i dla klasy negatywnej. Innymi słowy:\n",
    "\n",
    "$$ \\text{Balanced Accuracy} = \\frac{1}{2}(\\text{TPR} + \\text{TNR}) $$\n",
    "\n",
    "czyli średnią z czułości (TPR) i specyficzności (TNR).  \n",
    "Jest to metryka odporna na niezbalansowanie zbiorów danych.\n",
    "\n",
    "Zwracasz **twarde etykiety (0/1)**.\n",
    "\n",
    "W notebooku znajduje się funkcja `evaluate_algorithm`, dzięki której przetestujesz swój model na `valid.csv`.\n",
    "\n",
    "Za to zadanie możesz zdobyć pomiędzy 0 a 100 punktów. Wynik będzie skalowany liniowo w zależności od wartości Balanced Accuracy:\n",
    "\n",
    "- **Balanced Accuracy ≤ 0.7**: 0 punktów.\n",
    "- **Balanced Accuracy ≥ 0.87**: 100 punktów.\n",
    "- **Wartości pomiędzy 0.7 a 0.87**: skalowane liniowo.\n",
    "\n",
    "Wzór na wynik:  \n",
    "$$\n",
    "\\text{Punkty} = \n",
    "\\begin{cases} \n",
    "0 & \\text{dla } \\text{Balanced Accuracy} \\leq 0.7 \\\\\n",
    "100 \\times \\frac{\\text{Balanced Accuracy} - 0.7}{0.87 - 0.7} & \\text{dla } 0.7 < \\text{Balanced Accuracy} < 0.87 \\\\\n",
    "100 & \\text{dla } \\text{Balanced Accuracy} \\geq 0.87\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "## Ograniczenia\n",
    "\n",
    "Twój notebook będzie uruchamiany na Platformie Konkursowej:\n",
    "\n",
    "- **bez dostępu do internetu**\n",
    "- bez dostępu do GPU - **CPU only**\n",
    "- Limit czasu wykonania notebooka i ewaluacji na zbiorze testowym: **5 minut**\n",
    "- Lista dopuszczalnych bibliotek: `numpy`, `pandas`, `scikit-learn`, `matplotlib`, `tqdm`\n",
    "\n",
    "## Pliki zgłoszeniowe\n",
    "\n",
    "- Ten notebook uzupełniony o Twoje rozwiązanie:\n",
    "\n",
    "```python\n",
    "class SemanticChangeModel:\n",
    "    def fit(self, train_df):\n",
    "        ...\n",
    "    def predict_change(self, words: List[str]) -> List[int in {0,1}]:\n",
    "        ...\n",
    "```\n",
    "\n",
    "## Ewaluacja\n",
    "\n",
    "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`.\n",
    "\n",
    "Za to zadanie możesz zdobyć pomiędzy 0 a 100 punktów. Liczba punktów, którą zdobędziesz, będzie wyliczona na (tajnym) zbiorze testowym na Platformie Konkursowej na podstawie wyżej wspomnianego wzoru, zaokrąglona do liczby całkowitej. Jeśli Twoje rozwiązanie nie będzie spełniało powyższych kryteriów lub nie będzie wykonywać się prawidłowo, otrzymasz za zadanie 0 punktów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e26a3d",
   "metadata": {},
   "source": [
    "## Kod Startowy\n",
    "W tej sekcji inicjalizujemy środowisko poprzez zaimportowanie potrzebnych bibliotek i funkcji. Przygotowany kod ułatwi Tobie efektywne operowanie na danych i budowanie właściwego rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34507cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "\n",
    "FINAL_EVALUATION_MODE = False  # Podczas sprawdzania ustawimy tę flagę na True.\n",
    "\n",
    "import os, json, pickle, shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "EMB_DIR  = DATA_DIR / 'embeddings'\n",
    "EMB_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95827c2d",
   "metadata": {},
   "source": [
    "## Pobieranie danych (tylko lokalnie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c77ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "\n",
    "# Uwaga: Na platformie oceniającej Internet jest wyłączony.\n",
    "# Ten blok uruchamia się tylko lokalnie (gdy FINAL_EVALUATION_MODE == False).\n",
    "\n",
    "GDRIVE_FILES = [\n",
    "    ('1rUGgDZcpwRZ5sRHGxxEh2f7ZJ0DRVDPL', EMB_DIR / '1900-vocab.pkl'),\n",
    "    ('1cYXPhghcawbMZ6vU2XyJUq7NOpBIKj5E', EMB_DIR / '1900-w.npy'),\n",
    "    ('1ApLkBn2ylvLMKNlNtvkMVde6RxnLJolI', EMB_DIR / '1990-vocab.pkl'),\n",
    "    ('1B3NLInA4Ty3lUaHNQgxtDTKJNtG0t0T1', EMB_DIR / '1990-w.npy'),\n",
    "    ('1hrOfZOq3BV1K0tWe6HSZG-OiZkGlCiYT', DATA_DIR / 'train.csv'),\n",
    "    ('1vndyCuDCBP6zLvNkF_YsKHgTQgulTjt_', DATA_DIR / 'valid.csv'),\n",
    "]\n",
    "\n",
    "def download_data():\n",
    "    try:\n",
    "        import gdown\n",
    "    except Exception as e:\n",
    "        raise RuntimeError('Zainstaluj gdown lokalnie: `pip install gdown`') from e\n",
    "\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    EMB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for fid, out_path in GDRIVE_FILES:\n",
    "        if out_path.exists():\n",
    "            print(f'Pominięto pobieranie — plik już istnieje: {out_path.name}')\n",
    "            continue\n",
    "        url = f'https://drive.google.com/uc?id={fid}'\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'Pobieranie -> {out_path.name}')\n",
    "        gdown.download(url, str(out_path), quiet=False)\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    download_data()\n",
    "    print('Pobieranie zakończone.')\n",
    "else:\n",
    "    print('FINAL_EVALUATION_MODE=True — pomijam pobieranie (na platformie dane są dostarczone).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa2ab3",
   "metadata": {},
   "source": [
    "## Ładowanie embeddingów i zbiorów danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f499c495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900: V=100,000, dim=300\n",
      "1990: V=100,000, dim=300\n",
      "        word  label\n",
      "0     lichen      0\n",
      "1    imaging      1\n",
      "2      devil      0\n",
      "3    prayers      0\n",
      "4  frankfort      1\n",
      "\n",
      "        word  label\n",
      "0  coastline      0\n",
      "1       yoke      0\n",
      "2     report      1\n",
      "3   language      0\n",
      "4       barn      0\n",
      "train: 2495, valid: 832\n"
     ]
    }
   ],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "\n",
    "def load_histwords_decade(decade: int, emb_dir: Path):\n",
    "    vocab_path = emb_dir / f'{decade}-vocab.pkl'\n",
    "    w_path     = emb_dir / f'{decade}-w.npy'\n",
    "    with open(vocab_path, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    W = np.load(w_path)\n",
    "    # Normalizacja L2\n",
    "    W = W / (np.linalg.norm(W, axis=1, keepdims=True) + 1e-12)\n",
    "    w2i = {w:i for i,w in enumerate(vocab)}\n",
    "    return vocab, W, w2i\n",
    "\n",
    "# Wczytanie embeddingów\n",
    "vocab_1900, W1900, w2i_1900 = load_histwords_decade(1900, EMB_DIR)\n",
    "vocab_1990, W1990, w2i_1990 = load_histwords_decade(1990, EMB_DIR)\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    print(f'1900: V={len(vocab_1900):,}, dim={W1900.shape[1]}')\n",
    "    print(f'1990: V={len(vocab_1990):,}, dim={W1990.shape[1]}')\n",
    "\n",
    "# Wczytanie zbiorów train/valid\n",
    "train_path = DATA_DIR / 'train.csv'\n",
    "valid_path = DATA_DIR / 'valid.csv'\n",
    "assert train_path.exists() and valid_path.exists(), 'Brak train.csv / valid.csv w folderze data/'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "valid_df = pd.read_csv(valid_path)\n",
    "\n",
    "# Oczekiwane kolumny: word, label\n",
    "for c in ['word', 'label']:\n",
    "    assert c in train_df.columns and c in valid_df.columns, 'Oczekiwane kolumny: word, label'\n",
    "\n",
    "train_df['word'] = train_df['word'].astype(str).str.lower().str.strip()\n",
    "valid_df['word'] = valid_df['word'].astype(str).str.lower().str.strip()\n",
    "train_df['label'] = train_df['label'].astype(int)\n",
    "valid_df['label'] = valid_df['label'].astype(int)\n",
    "\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    print(train_df.head(5))\n",
    "    print()\n",
    "    print(valid_df.head(5))\n",
    "    print(f'train: {len(train_df)}, valid: {len(valid_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 sąsiadów w 1900:\n",
      "  intellect  (0.4798)\n",
      "  sagacity  (0.4282)\n",
      "  discernment  (0.3707)\n",
      "  understanding  (0.3688)\n",
      "  tact  (0.3659)\n",
      "  skill  (0.3643)\n",
      "  humanity  (0.3641)\n",
      "  honesty  (0.3598)\n",
      "  ability  (0.3517)\n",
      "  sensibility  (0.3512)\n",
      "\n",
      "Top 10 sąsiadów w 1990:\n",
      "  iq  (0.3773)\n",
      "  wechsler  (0.3542)\n",
      "  cia  (0.3362)\n",
      "  hinsley  (0.3301)\n",
      "  artificial  (0.3264)\n",
      "  afric  (0.3202)\n",
      "  binet  (0.3191)\n",
      "  aptitude  (0.3152)\n",
      "  abwehr  (0.3108)\n",
      "  abilities  (0.3070)\n"
     ]
    }
   ],
   "source": [
    "def print_neighbors(word, V, vocab, w2i, label):\n",
    "    vec = V[w2i[word]]\n",
    "    sims = V @ vec\n",
    "    sims[w2i[word]] = -np.inf\n",
    "    top = np.argsort(-sims)[:10]\n",
    "    print(f\"\\nTop 10 sąsiadów w {label}:\")\n",
    "    for i in top:\n",
    "        print(f\"  {vocab[i]}  ({sims[i]:.4f})\")\n",
    "\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    print_neighbors(\"intelligence\", W1900, vocab_1900, w2i_1900, \"1900\")\n",
    "    print_neighbors(\"intelligence\", W1990, vocab_1990, w2i_1990, \"1990\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b201a2",
   "metadata": {},
   "source": [
    "## Twoje rozwiązanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7dad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################  ZMODYFIKUJ TYLKO TĘ KOMÓRKĘ  #########################\n",
    "# Zaimplementuj swój model jako klasę z metodami:\n",
    "#   - __init__       : zapisz osadzenia (embeddings) + podstawowe hiperparametry\n",
    "#   - fit(train_df)  : trenuj na oznaczonych danych\n",
    "#   - predict_change(words) : zwróć etykiety dla podanej listy słów\n",
    "#\n",
    "# Kod ewaluacyjny otrzyma instancję klasy i będzie zakładał jedynie, że posiada\n",
    "# metodę .predict_change(words).\n",
    "\n",
    "class SemanticChangeModel:\n",
    "    def __init__(self, W1900, W1990, w2i_1900, w2i_1990):\n",
    "        \"\"\"\n",
    "        Przechowuj tutaj wszystkie kosztowne / globalne obiekty. Możesz zbudować\n",
    "        dodatkowe struktury w metodzie fit().\n",
    "\n",
    "        Parametry\n",
    "        ----------\n",
    "        W1900, W1990 : np.ndarray [V, D]\n",
    "            Znormalizowane osadzenia (embeddings) dla lat 1900 i 1990.\n",
    "        w2i_1900, w2i_1990 : dict\n",
    "            Mapowanie słowo -> indeks wiersza w osadzeniach.\n",
    "        \"\"\"\n",
    "        self.W1900 = W1900\n",
    "        self.W1990 = W1990\n",
    "        self.w2i_1900 = w2i_1900\n",
    "        self.w2i_1990 = w2i_1990\n",
    "\n",
    "        # Możesz dodać więcej parametrów i metod według potrzeb\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"\n",
    "        Zbuduj swój model, korzystając z oznaczonych danych treningowych.\n",
    "\n",
    "        Parametry\n",
    "        ----------\n",
    "        train_df : pd.DataFrame\n",
    "            Musi zawierać przynajmniej kolumny ['word', 'label'].\n",
    "        \"\"\"\n",
    "        # TODO: zastąp ten placeholder swoją rzeczywistą logiką dopasowywania.\n",
    "        pass\n",
    "    \n",
    "    def predict_change(self, words):\n",
    "        \"\"\"\n",
    "        Przewiduje, czy słowa znacząco zmieniły swoje znaczenie.\n",
    "\n",
    "        Parametry\n",
    "        ----------\n",
    "        words : list of str\n",
    "            Lista słów do sklasyfikowania.\n",
    "\n",
    "        Zwraca\n",
    "        -------\n",
    "        list of int\n",
    "            Lista 0 lub 1 (1 = 'zmienione') dla każdego słowa.\n",
    "        \"\"\"\n",
    "        # TODO: zastąp ten placeholder swoją rzeczywistą logiką predykcji.\n",
    "        return [random.choice([0,1]) for _ in words]\n",
    "\n",
    "\n",
    "MODEL = SemanticChangeModel(W1900, W1990, w2i_1900, w2i_1990)\n",
    "MODEL.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e5527a",
   "metadata": {},
   "source": [
    "## Ewaluacja\n",
    "\n",
    "Uruchomienie poniższej komórki pozwoli sprawdzić, ile punktów zdobyłoby Twoje rozwiązanie na danych walidacyjnych.\n",
    "\n",
    "Upewnij się przed wysłaniem, że cały notebook wykonuje się od początku do końca bez błędów i bez ingerencji użytkownika po wykonaniu polecenia `Run All`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39991ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Liczba próbek: 832\n",
      "Balanced accuracy: 0.5157\n",
      "Wynik punktowy: 0\n"
     ]
    }
   ],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "def compute_score(bal_acc: float) -> float:\n",
    "    \"\"\"\n",
    "    Oblicza wynik punktowy na podstawie wartości zbalansowanej dokładności.\n",
    "\n",
    "    :param bal_acc: Wartość float w zakresie [0.0, 1.0]\n",
    "    :return: Wynik punktowy zgodny z określoną funkcją\n",
    "    \"\"\"\n",
    "    if bal_acc <= 0.7:\n",
    "        return 0\n",
    "    elif 0.7 < bal_acc < 0.87:\n",
    "        return int(round(100 * (bal_acc - 0.7) / (0.87 - 0.7)))\n",
    "    else:\n",
    "        return 100\n",
    "\n",
    "\n",
    "def evaluate_algorithm(dataset_df, model, verbose=False):\n",
    "    \"\"\"\n",
    "    Ewaluacja modelu wykrywania zmiany znaczenia słów na podanym zbiorze danych.\n",
    "\n",
    "    Parametry\n",
    "    ----------\n",
    "    dataset_df : pd.DataFrame\n",
    "        Oznaczony zbiór danych z kolumnami:\n",
    "          - 'word'  : słowo (string)\n",
    "          - 'label' : etykieta 0 = stabilne, 1 = zmienione\n",
    "\n",
    "    model : obiekt\n",
    "        Obiekt posiadający metodę:\n",
    "            predict_change(words: list[str]) -> list[int] {0,1}\n",
    "\n",
    "    verbose : bool\n",
    "        Jeśli True, wypisuje dodatkowe informacje.\n",
    "\n",
    "    Zwraca\n",
    "    -------\n",
    "    points : float\n",
    "        Wynik punktowy oparty na zbalansowanej dokładności.\n",
    "    \"\"\"\n",
    "\n",
    "    # Wyodrębnij słowa i etykiety z datasetu\n",
    "    words = dataset_df[\"word\"].astype(str).tolist()\n",
    "    ys = dataset_df[\"label\"].astype(int).tolist()\n",
    "\n",
    "    # Pobierz predykcje dla całej listy słów\n",
    "    preds = model.predict_change(words)\n",
    "\n",
    "    # Konwersja predykcji i etykiet na tablice numpy\n",
    "    preds = np.array(preds, dtype=np.int32)\n",
    "    ys = np.array(ys, dtype=np.int32)\n",
    "\n",
    "    # Zbalansowana dokładność\n",
    "    bal_acc = balanced_accuracy_score(ys, preds)\n",
    "\n",
    "    # Konwersja dokładności na punkty konkursowe\n",
    "    points = compute_score(bal_acc)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nLiczba próbek: {len(dataset_df)}\")\n",
    "        print(f\"Balanced accuracy: {bal_acc:.4f}\")\n",
    "        print(f\"Wynik punktowy: {points}\")\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    _ = evaluate_algorithm(valid_df, MODEL, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OlimpiadaAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
