{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentacja danych multispektralnych\n",
    "\n",
    "![satelita](https://hackmd.io/_uploads/r1lA5vkx-l.jpg)\n",
    "\n",
    "*Obraz wygenerowany przez narzędzie generowania obrazów DeepAI.*\n",
    "\n",
    "## Wstęp\n",
    "\n",
    "Ziemia nieustannie się zmienia &mdash; miasta się rozrastają, granice lasów przesuwają, a lodowce topnieją. Aby zrozumieć te procesy, naukowcy i inżynierowie coraz częściej sięgają po dane satelitarne. Dzięki nim możemy obserwować naszą planetę z kosmosu, monitorować stan środowiska i wykrywać zmiany, których często nie widać „gołym okiem”.\n",
    "\n",
    "Jednym z kluczowych rodzajów takich danych są obrazy multispektralne, czyli zdjęcia wykonywane w wielu różnych zakresach promieniowania elektromagnetycznego. Każde z pasm dostarcza innych informacji o powierzchni Ziemi, a ściślej o tym, w jaki sposób dany materiał pochłania i odbija światło. Przykładowo: w świetle widzialnym dostrzegamy naturalne barwy roślin i gleby, natomiast podczerwień pozwala ocenić kondycję roślinności czy wilgotność gruntu.\n",
    "\n",
    "Technologia ta umożliwia nieinwazyjne tworzenie map, analizę terenów uprawnych (np. pod kątem żyzności), śledzenie postępu suszy, a także monitorowanie zanieczyszczeń czy skutków katastrof naturalnych. Obrazy multispektralne stanowią dziś jeden z fundamentów nowoczesnej teledetekcji (ang. remote sensing).\n",
    "\n",
    "Każdy materiał na Ziemi &mdash; woda, piasek, beton czy trawa - odbija promieniowanie w charakterystyczny dla siebie sposób. Ten unikalny wzór nazywamy sygnaturą spektralną. Analizując te sygnatury w różnych pasmach, możemy precyzyjnie zidentyfikować obiekty widoczne na zdjęciu.\n",
    "\n",
    "W praktyce dane te bywają jednak zakłócone przez czynniki atmosferyczne (chmury, parę wodną, pyły) oraz drobne błędy pomiarowe czujników. Dlatego, zanim obrazy multispektralne posłużą do analizy, muszą zostać poddane odpowiedniemu przetworzeniu i korekcji.\n",
    "\n",
    "## Zadanie\n",
    "\n",
    "Twoim zadaniem jest przygotowanie klasy przetwarzającej zbiór danych oraz nauczenie modelu segmentującego obrazy multispektralne (mapy terenu).\n",
    "\n",
    "Pierwszy etap zadania polega na stworzeniu funkcji, która przetworzy dane wejściowe w sposób maksymalizujący skuteczność modelu (bez użycia etykiet). Aby zwiększyć różnorodność zbioru treningowego i poprawić zdolność generalizacji, możesz zastosować różne techniki augmentacji danych, takie jak obrót, skalowanie czy dodawanie szumu (albo inne metody, które uznasz za stosowne).\n",
    "\n",
    "Podczas analizy danych postaraj się dobrać **minimalny** zestaw pasm (kanałów), który pozwoli uzyskać wysoką jakość segmentacji. Zastanów się, które kanały niosą najwięcej informacji - przykładowo: czy podczerwień wpływa na detekcję roślinności? Wykorzystanie wszystkich pasm nie zawsze jest konieczne; często lepsze rezultaty daje selekcja tylko tych, które zawierają kluczowe informacje dla rozróżnianych klas. Pamiętaj, że nie musisz ograniczać się do surowych wartości kanałów - w procesie przetwarzania możesz wygenerować zupełnie nowe reprezentacje cech.\n",
    "\n",
    "Drugim etapem jest stworzenie rozwiązania do segmentacji obrazów multispektralnych, czyli przypisanie każdemu pikselowi jednej z czterech klas: wody, lądu, roślinności lub terenów przemysłowych (zgodnie z poniższym przykładem). W tym celu możesz wykorzystać biblioteki takie jak PyTorch i scikit-learn.\n",
    "\n",
    "![mapy_segmentacji](https://live.staticflickr.com/65535/54927654414_b325b31a02_c.jpg)\n",
    "\n",
    "Do dyspozycji masz opatrzony etykietami zbiór treningowy i walidacyjny, na których możesz testować swoje podejście. Ostateczna ocena modelu zostanie przeprowadzona na ukrytym zbiorze testowym. Każdy obraz wejściowy składa się z 12 pasm spektralnych, jednak decyzja o tym, ile i które z nich wykorzystasz, należy do Ciebie.\n",
    "\n",
    "## Opis danych\n",
    "\n",
    "Dane podzielono na osobne zbiory:\n",
    "\n",
    "- **treningowy** - $48$ próbek (obrazów),\n",
    "\n",
    "- **walidacyjny** - $16$ próbek (obrazów).\n",
    "\n",
    "Do ostatecznej oceny posłuży zbiór **testowy** składający się z $96$ próbek (obrazów), do którego nie masz dostępu.\n",
    "Każda próbka to obraz o wymiarach $30 \\times 30$ pikseli. Każdy piksel posiada przypisaną etykietę klasy (maskę segmentacji).\n",
    "Każdy piksel opisany jest przez $12$ kanałów odpowiadających pomiarom odbicia światła w różnych zakresach długości fali.\n",
    "\n",
    "## Kryterium oceny\n",
    "\n",
    "Twój wynik zależy od dwóch czynników: jakości segmentacji na ukrytym zbiorze testowym oraz liczby kanałów, które zdecydujesz się wykorzystać na wejściu modelu.\n",
    "\n",
    "Pierwszy składnik funkcji oceny związany jest z liczbą wykorzystanych kanałów $N\\_channels$. Oryginalnie każdy piksel złożony jest z 12 kanałów i za użycie wszystkich kanałów otrzymasz 0 punktów za tę część zadania. Wszystkie rozwiązania stosujące co najwyżej 3 kanały otrzymają komplet punktów za ten składnik funkcji oceny, z kolei rozwiązania używające $\\lbrace 4, 5, 6, ..., 11\\rbrace$ kanałów zostaną ocenione według kwadratowej funkcji skali:\n",
    "\n",
    "$$\\mathtt{channel\\_evaluation} = \n",
    "\\begin{cases} \n",
    "    0 &\\quad \\text{jeżeli }  N\\_channels \\geq 12 \\\\\n",
    "    100 &\\quad \\text{jeżeli }  N\\_channels \\leq 3 \\\\\n",
    "    100 \\cdot \\left( \\dfrac{12 - N\\_channels}{12 - 3} \\right)^2 &\\quad \\text{w pozostałych przypadkach}.\n",
    "\\end{cases}$$\n",
    "\n",
    "Przykładowo, za zastosowanie 10 kanałów otrzymasz jedynie 5 punktów za tę część zadania, pomnożone przez współczynnik wynoszący $0.25$.\n",
    "Drugi składnik funkcji oceny związany jest z jakością segmentacji dla map zastosowanych w zadaniu. Wykorzystamy do tego miarę $\\text{IoU}$ (Intersection over Union), która ocenia stosunek ilości prawidłowo sklasyfikowanych pikseli danej klasy w danym obrazie, w odniesieniu do ilości wszystkich pikseli tej klasy występujących w rzeczywistej mapie (*ground truth*) lub predykcji modelu. Finalnie, policzona zostanie średnia po wszystkich klasach oraz obrazach znajdujących się w zbiorze testowym. Dla każdego obrazka liczona będzie średnia tylko po klasach, które pojawiają się w *ground truth*.\n",
    "\n",
    "$$\\text{IoU} = \\dfrac{1}{M \\cdot N} \\cdot \\sum\\limits_{i=1}^{N} \\sum\\limits_{j=1}^{M_i} \\dfrac{\\text{ilość prawidłowo sklasyfikowanych pikseli j-tej klasy w i-tej mapie}}{\\text{ilość pikseli j-tej klasy w łącznym rzeczywistym obszarze oraz predykcji modelu dla i-tej mapy }}$$\n",
    "\n",
    "gdzie $N$ to ilość obrazów w danym zbiorze (np. testowym), zaś $M_i$ jest liczbą klas rzeczywiście występującą w $i$-tej mapie. Jeśli średnie $\\text{IoU}$ wyniesie nie więcej niż 0.6, otrzymasz za tę część zadania 0 punktów, a jeżeli co najmniej 0.8, wówczas otrzymasz za tę część zadania pełną pulę punktów.\n",
    "\n",
    "$$\\mathtt{segmentation\\_evaluation} = \n",
    "\\begin{cases} \n",
    "    0 &\\quad \\text{jeżeli }  \\text{IoU} \\leq 0.6 \\\\\n",
    "    100 &\\quad \\text{jeżeli }  \\text{IoU} \\geq 0.8 \\\\\n",
    "    100 \\cdot \\dfrac{\\text{IoU} - 0.6}{0.8 - 0.6} &\\quad \\text{w pozostałych przypadkach}\n",
    "\\end{cases}$$\n",
    "\n",
    "Przykład obliczania $\\text{IoU}$ dla jednej z klas (wyrażonej za pomocą niebieskich kwadratów) znajduje się na poniższym obrazku. Wynik końcowy $\\text{IoU}$ jest uśredniany po wszystkich klasach obecnych w danym obrazie, a także po wszystkich obrazach w zbiorze.\n",
    "\n",
    "![IoU](https://live.staticflickr.com/65535/54922482577_1a5222581f_b.jpg)\n",
    "\n",
    "Ostateczny wynik za zadanie będzie stanowił $25\\%$ oceny za ilość użytych kanałów oraz $75\\%$ punktów za jakość segmentacji, zgodnie ze wzorem:\n",
    "\n",
    "$$\\text{score} = 0.25 \\cdot \\mathtt{channel\\_evaluation} + 0.75 \\cdot \\mathtt{segmentation\\_evaluation}$$\n",
    "\n",
    "**UWAGA!** Jeśli $\\text{IoU}$ wyniesie mniej niż 0.5, otrzymasz 0 punktów za całe zadanie, niezależnie od użytej ilości kanałów!\n",
    "\n",
    "\n",
    "## Ograniczenia\n",
    "\n",
    "- Twoje rozwiązanie będzie testowane na Platformie Konkursowej bez dostępu do Internetu oraz w środowisku z GPU. \n",
    "- Trening modelu i ewaluacja Twojego finalnego rozwiązania na Platformie Konkursowej nie mogą trwać dłużej niż 5 minut z użyciem GPU.\n",
    "- Klasa dokonująca wstępnego przekształcenia danych `YourPreprocessing` nie może w żaden sposób korzystać z etykiet zbiorów danych (może tylko przetwarzać same próbki), a segmentacja ma być wykonywana bezpośrednio w klasie `YourModel`.\n",
    "\n",
    "## Pliki Zgłoszeniowe\n",
    "\n",
    "Ten notebook uzupełniony o Twoje rozwiązanie (patrz klasa `YourModel` oraz klasa `YourPreprocessing`), w którym przygotujesz zestaw zawierający przekształcanie danych z potencjalną redukcją i modyfikacją kanałów oraz model dokonujący segmentacji na przetworzonych danych.\n",
    "\n",
    "## Ewaluacja\n",
    "\n",
    "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na True.\n",
    "\n",
    "Za to zadanie możesz zdobyć pomiędzy 0 a 100 punktów. Liczba punktów, którą zdobędziesz, będzie wyliczona na (tajnym) zbiorze testowym na Platformie Konkursowej na podstawie wyżej wspomnianego wzoru, zaokrąglona do liczby całkowitej. Jeśli Twoje rozwiązanie nie będzie spełniało powyższych kryteriów, nie będzie wykonywać się prawidłowo lub zostanie wykryta próba oszustwa, otrzymasz za zadanie 0 punktów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kod Startowy\n",
    "\n",
    "W tej sekcji inicjalizujemy środowisko poprzez zaimportowanie potrzebnych bibliotek i funkcji. Przygotowany kod ułatwi Tobie efektywne operowanie na danych i budowanie właściwego rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "FINAL_EVALUATION_MODE = False  # Podczas sprawdzania ustawimy tą flagę na True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "# Dodatkowe biblioteki, któe możesz wykorzystać w Twoim rozwiązaniu\n",
    "import xgboost\n",
    "import sklearn\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIR = \"./data\"\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_DIR, \"train.npz\")\n",
    "VALID_DATA_PATH = os.path.join(DATA_DIR, \"valid.npz\")\n",
    "\n",
    "assert torch.cuda.is_available(), \"Nie znaleziono karty graficznej (GPU)!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "seed = 12345\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ładowanie Danych\n",
    "Za pomocą poniższego kodu wczytujemy dane zawierające obrazy multispektralne oraz odpowiadające im maski segmentacji. Dane te będą podstawą do trenowania i walidacji Twojego modelu segmentującego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "# Komórka zawierająca funkcje pomocnicze do przygotowania danych.\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Klasa zbioru danych multispektralnych.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path: str):\n",
    "        data = np.load(data_path)\n",
    "        self.bands = data[\"bands\"]\n",
    "        self.segmentations = data[\"segmentations\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Zwraca liczbę próbek w zbiorze danych.\"\"\"\n",
    "        return self.bands.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Zwraca próbkę o indeksie idx - jej pasma multispektralne oraz segmentację.\"\"\"\n",
    "        bands = self.bands[idx]\n",
    "        segmentations = self.segmentations[idx]\n",
    "\n",
    "        bands = torch.from_numpy(bands).float()\n",
    "        segmentations = torch.from_numpy(segmentations).long()\n",
    "\n",
    "        return bands, segmentations\n",
    "\n",
    "def setup_data():\n",
    "    \"\"\"\n",
    "    Pobiera zbiory danych wykorzystane w zadaniu.\n",
    "    \"\"\"\n",
    "    import gdown\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(TRAIN_DATA_PATH):\n",
    "        url = \"https://drive.google.com/uc?id=1Nfv3Kd9W8ypjr8RL1jY3VF3yTKU934lz\"\n",
    "        gdown.download(url, TRAIN_DATA_PATH, fuzzy=True)\n",
    "    \n",
    "    if not os.path.exists(VALID_DATA_PATH):\n",
    "        url = \"https://drive.google.com/uc?id=1WUwayYErm4CXI7zHUAmZmi23doIKmDm3\"\n",
    "        gdown.download(url, VALID_DATA_PATH, fuzzy=True)\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    setup_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kod z Kryterium Oceniającym\n",
    "\n",
    "Kod, zbliżony do poniższego, będzie używany do oceny rozwiązania na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "def calculate_miou(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Kalkuluje metrykę mIoU (mean Intersection over Union) używaną do oceny modelu.\n",
    "    Funkcja pomocnicza wykorzystywana przy ocenie rozwiązania.\n",
    "    \"\"\"\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    assert y_true.device == y_pred.device\n",
    "\n",
    "    num_classes = 4\n",
    "    device = y_true.device\n",
    "    batch_size = y_true.shape[0]\n",
    "    y_true_flat = y_true.reshape(batch_size, y_true.shape[1] * y_true.shape[2])\n",
    "    y_pred_flat = y_pred.reshape(batch_size, y_pred.shape[1] * y_pred.shape[2])\n",
    "\n",
    "    # Końcowa średnia jest liczona tylko dla klas obecnych w danych referencyjnych (ground truth)\n",
    "    intersections = torch.zeros((batch_size, num_classes), dtype=torch.float32, device=device)\n",
    "    unions = torch.zeros((batch_size, num_classes), dtype=torch.float32, device=device)\n",
    "    true_present = torch.zeros((batch_size, num_classes), dtype=torch.bool, device=device)\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        y_true_c = (y_true_flat == cls)\n",
    "        y_pred_c = (y_pred_flat == cls)\n",
    "        true_present[:, cls] = torch.any(y_true_c, dim=1)\n",
    "\n",
    "        intersections[:, cls] = torch.sum(y_true_c & y_pred_c, dim=1).to(torch.float32)\n",
    "        unions[:, cls] = torch.sum(y_true_c | y_pred_c, dim=1).to(torch.float32)\n",
    "\n",
    "    # Oblicza liczbę istotnych klas dla każdej próbki\n",
    "    num_present_classes = torch.sum(true_present, dim=1).to(torch.float32)\n",
    "\n",
    "    # Mimo że obliczenia są wykonywane dla wszystkich klas, sumujemy tylko te klasy, które faktycznie występują (w danych referencyjnych)\n",
    "    iou_per_class = torch.nan_to_num(intersections / unions, nan=0.0)\n",
    "    sum_iou = torch.sum(iou_per_class * true_present, dim=1)\n",
    "    miou_scores = torch.nan_to_num(sum_iou / num_present_classes, nan=0.0).tolist()\n",
    "    assert len(miou_scores) == batch_size\n",
    "\n",
    "    return miou_scores\n",
    "\n",
    "\n",
    "def calculate_channel_count(dataloader):\n",
    "    \"\"\"\n",
    "    Funkcja pomocnicza wykorzystywana przy ocenie rozwiązania.\n",
    "    Kalkuluje ilość pasm wykorzystywanych przy treningu i ewaluacji modelu.\n",
    "    \"\"\"\n",
    "    tensors = dataloader.dataset.tensors\n",
    "    \n",
    "    if len(tensors) != 2:\n",
    "        raise ValueError(\"W zbiorze danych powinny znajdować się tylko etykiety i obrazy (__getitem__ powinien zwracać krotkę o wymiarowości 2)\")\n",
    "    \n",
    "    x, _ = tensors\n",
    "    \n",
    "    # x.shape [dataset size, channels, height, width]\n",
    "    if x.ndim != 4:\n",
    "        raise ValueError(\"Przetworzone dane muszą posiadać 4 wymiary [batch size, channels, height, width]\")\n",
    "\n",
    "    if x.shape[0] < 15: #zbiór walidacyjny jest najmniejszy i ma 15 próbek \n",
    "        raise ValueError(f\"Pierwszy wymiar jest zarezerwowany dla rozmiaru datasetu, Twój kod nie powinien go zmieniać!\")\n",
    "\n",
    "    if x.shape[2] != 30 or x.shape[3] != 30:\n",
    "        raise ValueError(\"Przetworzone dane muszą mieć wymiary 30x30 na 3 i 4 wymiarze (.shape[2] == .shape[3] == 30)\")\n",
    "\n",
    "    channels_count = x.shape[1]\n",
    "    return channels_count\n",
    "\n",
    "def transform_dataset(preprocessing, dataset:BaseDataset) -> TensorDataset:\n",
    "    \"\"\"\n",
    "    Przetwarza wskazany zbiór danych i zachowuje go w pamięci komputera (RAM). \n",
    "    Wywołuje zaimplementowaną przez uczestnika funkcję .transform w klasie przygotowującej zbiory danych.\n",
    "    \"\"\"\n",
    "    processed_labels = []\n",
    "    processed_images = []\n",
    "    \n",
    "    for raw_image, label in dataset:\n",
    "        processed_labels.append(label.clone())\n",
    "        \n",
    "        transformed_image = preprocessing.transform(raw_image.clone())\n",
    "        processed_images.append(transformed_image)\n",
    "\n",
    "    labels_tensor = torch.stack(processed_labels) \n",
    "    images_tensor = torch.stack(processed_images)  \n",
    "    memory_dataset = TensorDataset(images_tensor, labels_tensor)\n",
    "    return memory_dataset\n",
    "\n",
    "def evaluate(train_model, preprocessing, data_path: str):\n",
    "    \"\"\"\n",
    "    Główna funkcja oceniająca zadanie. \n",
    "    Taka sama funkcja będzie wywołana na Platformie Konkursowej.\n",
    "\n",
    "    1. Dopasowuje klasę przetwarzania danych na zbiorze treningowym.\n",
    "    2. Przetwarza wskazany zbiór danych za pomocą dopasowanej klasy.\n",
    "    3. Ocenia model za pomocą metryki mIoU na wskazanym przetworzonym zbiorze danych.\n",
    "    4. Ocenia ilość pasm wykorzystanych przy ocenie modelu - sprawdza kształt danych.\n",
    "    \"\"\"\n",
    "\n",
    "    # Wczytuje zbiór treningowy i dopasowuje na nim klasę przygotowywania danych \n",
    "    train_ds = BaseDataset(data_path=TRAIN_DATA_PATH)\n",
    "    preprocessing = preprocessing()\n",
    "    assert hasattr(preprocessing, \"fit\"), \"Funkcja przygotowująca dane musi implementować metodę .fit\"\n",
    "    preprocessing.fit(train_ds)\n",
    "    \n",
    "    # Wczytuje docelowy zbiór danych i przetwarza go za pomocą klasy słuącej do przygotowywania danych\n",
    "    target_ds = BaseDataset(data_path=data_path)\n",
    "    assert hasattr(preprocessing, \"transform\"), \"Funkcja przygotowująca dane musi implementować metodę .transform\"\n",
    "    transformed_dataset = transform_dataset(preprocessing=preprocessing, dataset=target_ds)\n",
    "    dataloader = DataLoader(transformed_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    model = train_model()\n",
    "\n",
    "    if hasattr(model, \"to\") and callable(getattr(model, \"to\", None)):\n",
    "        model = model.to(DEVICE)\n",
    "\n",
    "    if hasattr(model, \"eval\") and callable(getattr(model, \"eval\", None)):\n",
    "        model.eval()\n",
    "\n",
    "    mious = []\n",
    "\n",
    "    # Ocenia model za pomocą metryki mIoU\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for x, y in dataloader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            if hasattr(y_pred, \"to\") and callable(getattr(y_pred, \"to\", None)):\n",
    "                y_pred = y_pred.to(DEVICE)\n",
    "            if not torch.is_tensor(y_pred):\n",
    "                y_pred = torch.tensor(y_pred)\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "            assert y_pred.shape == y.shape\n",
    "            assert y_pred.max() <= 4 and y_pred.min() >= 0\n",
    "\n",
    "            miou = calculate_miou(y, y_pred)\n",
    "            mious.extend(miou)\n",
    "\n",
    "    # Ocenia ilość pasm wykorzystanych przy ocenie modelu\n",
    "    channels_count = calculate_channel_count(dataloader=dataloader)\n",
    "    \n",
    "    # Wylicza średnią mIoU po wszystkich próbkach\n",
    "    miou = sum(mious) / len(mious)\n",
    "\n",
    "    return miou, channels_count\n",
    "    \n",
    "def compute_score(miou, channels_count):\n",
    "    \"\"\"\n",
    "    Oblicza wynik za zadanie, kalkuluje ilość ostatecznych punktów za zadanie za pomocą wzoru podanego w treści zadania.\n",
    "    Taka sama funkcja będzie wywołana na Platformie Konkursowej.\n",
    "    \"\"\"\n",
    "    band_score = max(0, min(100, 100 * ((12 - channels_count) / (12 - 3))**2))\n",
    "    miou_score = max(0, min(100, 100 * (miou - 0.6) / (0.8 - 0.6)))\n",
    "\n",
    "    print(f\"Liczba kanałów: {channels_count}\")\n",
    "    print(f\"mIoU: {miou:.3f} \\n\")\n",
    "\n",
    "    print(f\"Wynik dot. kanałów: {band_score:.3f}\")\n",
    "    print(f\"Wynik dot. mIoU: {miou_score:.3f}\")\n",
    "\n",
    "    if miou_score < 0.5:\n",
    "        total_score = int(0)\n",
    "    else:\n",
    "        total_score = 0.25 * band_score + 0.75 * miou_score\n",
    "        total_score = int(round(total_score))\n",
    "    print(f\"Estymowana liczba punktów za zadanie: {total_score}\")\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykładowe Rozwiązanie\n",
    "\n",
    "Poniżej przedstawiamy uproszczone rozwiązanie oparte o regresję liniową, które może posłużyć jako przykład demonstrujący działanie notatnika jak i punkt wyjścia do stworzenia Twojego rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "class BasicPreprocessing():\n",
    "  \"\"\"\n",
    "  Przykładowa implementacja klasy przetwarzania zbioru danych.\n",
    "\n",
    "  Jest to tylko przykładowe rozwiązanie, które nie redukuje liczby kanałów.\n",
    "  Z im mniejszej liczby kanałów skorzystasz, tym więcej otrzymasz punktów za tę część zadania.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    self.std_per_channel = None\n",
    "    \n",
    "  def fit(self, dataset:BaseDataset):\n",
    "\n",
    "    # Zbiera wszystkie obrazy do jednej macierzy [N_próbek, 12, 30, 30]\n",
    "    images = []\n",
    "    for item in dataset:\n",
    "        image_tensor, _ = item\n",
    "        images.append(image_tensor)\n",
    "    images_tensor = torch.stack(images)  # shape: [N, 12, 30, 30]\n",
    "\n",
    "    # Oblicza std (odchylenie standardowe) po wymiarach: (0: próbka, 2: H, 3: W)\n",
    "    self.std_per_channel = images_tensor.std(dim=(0, 2, 3))\n",
    "\n",
    "    return self\n",
    "\n",
    "  def transform(self, image_tensor: torch.Tensor) -> torch.Tensor:          \n",
    "      # Zmienia kształt średniej na [12, 1, 1], aby umożliwić broadcasting względem [12, 30, 30].\n",
    "      # Pamiętaj, to tylko przykładowe rozwiązanie, samo podzielenie przez std nie jest najbardziej efektywnym rozwiązaniem.\n",
    "      std_reshaped = self.std_per_channel.view(-1, 1, 1)\n",
    "      \n",
    "      return image_tensor / std_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "class BasicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(12, 4)\n",
    "    \n",
    "    def forward(self, bands):\n",
    "        # bands.shape [b, c, h, w]\n",
    "        return self.linear(bands.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening Przykładowego Modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "def train_basic_model():\n",
    "\n",
    "    epochs = 40\n",
    "    lr = 0.001\n",
    "    batch_size = 8\n",
    "    model = BasicModel()\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # Przygotowuje parametry przetwarzania wstępnego danych tylko z użyciem\n",
    "    # zbioru treningowego.\n",
    "\n",
    "    raw_train_ds = BaseDataset(data_path=TRAIN_DATA_PATH)\n",
    "    raw_valid_ds = BaseDataset(data_path=VALID_DATA_PATH)\n",
    "\n",
    "    preprocessing = BasicPreprocessing()\n",
    "    preprocessing.fit(raw_train_ds)\n",
    "\n",
    "    train_ds = transform_dataset(preprocessing=preprocessing, dataset=raw_train_ds)\n",
    "    valid_ds = transform_dataset(preprocessing=preprocessing, dataset=raw_valid_ds)\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_dataloader, total=len(train_dataloader), desc=\"Training\"):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0\n",
    "            mious = []\n",
    "            for x, y in tqdm(valid_dataloader, total=len(valid_dataloader), desc=\"Validation\"):\n",
    "                x = x.to(DEVICE)\n",
    "                y = y.to(DEVICE)\n",
    "\n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                y_pred = torch.argmax(y_pred, dim=1)\n",
    "                miou = calculate_miou(y, y_pred)\n",
    "                mious.extend(miou)\n",
    "            \n",
    "            valid_loss = valid_loss / len(valid_dataloader)\n",
    "            print(f\"Epoch {epoch+1} loss: {valid_loss}, mIoU: {sum(mious) / len(mious)}\")\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja Przykładowego Rozwiązania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    miou, channels_count = evaluate(train_basic_model, BasicPreprocessing, VALID_DATA_PATH)\n",
    "    print(\"-\"*50)\n",
    "    compute_score(miou, channels_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twoje rozwiązanie\n",
    "W tej sekcji należy umieścić Twoje rozwiązanie. Wprowadzaj zmiany wyłącznie tutaj!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nie zmieniaj nazwy klasy\n",
    "# Ta klasa może jedynie przetwarzać próbki, nie może korzystać z etykiet danych.\n",
    "# Żadna metoda nie może też wykonywać segmentacji.\n",
    "\n",
    "class YourPreprocessing():\n",
    "  def __init__(self):\n",
    "    pass\n",
    "    \n",
    "  def fit(self, dataset: BaseDataset):\n",
    "    return dataset\n",
    "\n",
    "  def transform(self, image_tensor: torch.Tensor) -> torch.Tensor:\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, bands):\n",
    "        # losowe predykcje\n",
    "        segmentation = torch.randint(0, 4, (bands.shape[0], 1, 30, 30))\n",
    "        # Wykonuje one hot encoding ponieważ evaluate wykorzystuje torch.argmax\n",
    "        one_hot = torch.zeros(bands.shape[0], 4, 30, 30)\n",
    "        one_hot.scatter_(1, segmentation, 1)\n",
    "        return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nie zmieniaj nazwy funkcji\n",
    "def train_your_model():\n",
    "    return YourModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ewaluacja\n",
    "\n",
    "Uruchomienie komórki poniżej pozwoli sprawdzić, ile punktów zdobyłoby twoje rozwiązanie na danych walidacyjnych. Na Platformie Konkursowej Twoje rozwiązanie będzie oceniane na zbiorze testowym.\n",
    "\n",
    "Upewnij się przed wysłaniem, że cały notebook wykonuje się od początku do końca bez błędów i bez ingerencji użytkownika po wykonaniu polecenia `Run All`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    miou, channels_count = evaluate(train_your_model, YourPreprocessing, VALID_DATA_PATH)\n",
    "    print(\"-\"*50)\n",
    "    compute_score(miou, channels_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pamiętaj:** Podczas sprawdzania model (funkcja trenująca model) i funkcja przetwarzająca dane zostaną ocenione na zbiorze testowym, nie walidacyjnym!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "official_olimpAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
